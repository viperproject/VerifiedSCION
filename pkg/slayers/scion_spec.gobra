// Copyright 2022 ETH Zurich
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// +gobra

package slayers

import (
	"net"
	"github.com/google/gopacket"

	"github.com/scionproto/scion/pkg/addr"
	"github.com/scionproto/scion/pkg/slayers/path"
	"github.com/scionproto/scion/pkg/slayers/path/empty"
	"github.com/scionproto/scion/pkg/slayers/path/epic"
	"github.com/scionproto/scion/pkg/slayers/path/onehop"
	"github.com/scionproto/scion/pkg/slayers/path/scion"

	def "github.com/scionproto/scion/verification/utils/definitions"
	"github.com/scionproto/scion/verification/utils/slices"
)

pred (s *SCION) NonInitPathPool() {
	acc(&s.pathPool) &&
	acc(&s.pathPoolRaw) &&
	s.pathPool == nil &&
	s.pathPoolRaw == nil
}

pred (s *SCION) InitPathPool() {
	acc(&s.pathPool)     &&
	acc(&s.pathPoolRaw)  &&
	s.pathPool != nil    &&
	len(s.pathPool) == 4 &&
	// entry per path type
	// empty
	acc(&s.pathPool[empty.PathType])  &&
	s.pathPool[empty.PathType] != nil &&
	typeOf(s.pathPool[empty.PathType]) == type[empty.Path] &&
	// onehop
	acc(&s.pathPool[onehop.PathType])  &&
	s.pathPool[onehop.PathType] != nil &&
	typeOf(s.pathPool[onehop.PathType]) == type[*onehop.Path] &&
	s.pathPool[onehop.PathType].NonInitMem() &&
	// scion
	acc(&s.pathPool[scion.PathType])  &&
	s.pathPool[scion.PathType] != nil &&
	typeOf(s.pathPool[scion.PathType]) == type[*scion.Raw] &&
	s.pathPool[scion.PathType].NonInitMem() &&
	// epic
	acc(&s.pathPool[epic.PathType])  &&
	s.pathPool[epic.PathType] != nil &&
	typeOf(s.pathPool[epic.PathType]) == type[*epic.Path] &&
	s.pathPool[epic.PathType].NonInitMem() &&
	// raw path
	s.pathPoolRaw != nil &&
	s.pathPoolRaw.NonInitMem()
}

// Captures the same obligations as InitPathPool. Initially, I tried using a magic wand
// but they are a lot harder to use then just this predicate.
pred (s *SCION) InitPathPoolExceptOne(pathType path.Type) {
	acc(&s.pathPool)     &&
	acc(&s.pathPoolRaw)  &&
	s.pathPool != nil    &&
	len(s.pathPool) == 4 &&
	// entry per path type
	// empty
	(acc(&s.pathPool[empty.PathType]) &&
	s.pathPool[empty.PathType] != nil &&
	typeOf(s.pathPool[empty.PathType]) == type[empty.Path]) &&
	// onehop
	acc(&s.pathPool[onehop.PathType])  &&
	s.pathPool[onehop.PathType] != nil &&
	typeOf(s.pathPool[onehop.PathType]) == type[*onehop.Path] &&
	(pathType != onehop.PathType ==> s.pathPool[onehop.PathType].NonInitMem()) &&
	// scion
	acc(&s.pathPool[scion.PathType])  &&
	s.pathPool[scion.PathType] != nil &&
	typeOf(s.pathPool[scion.PathType]) == type[*scion.Raw] &&
	(pathType != scion.PathType ==> s.pathPool[scion.PathType].NonInitMem()) &&
	// epic
	acc(&s.pathPool[epic.PathType])  &&
	s.pathPool[epic.PathType] != nil &&
	typeOf(s.pathPool[epic.PathType]) == type[*epic.Path] &&
	(pathType != epic.PathType ==> s.pathPool[epic.PathType].NonInitMem()) &&
	// raw path
	s.pathPoolRaw != nil &&
	(pathType < len(s.pathPool) ==> s.pathPoolRaw.NonInitMem())
}

ghost
requires  s.InitPathPoolExceptOne(pathType)
decreases
pure func (s *SCION)lenPathPool(pathType path.Type) int {
	return unfolding s.InitPathPoolExceptOne(pathType) in len(s.pathPool)
}

ghost
requires  s.InitPathPoolExceptOne(pathType)
requires  0 <= pathType && pathType < s.lenPathPool(pathType)
decreases
pure func (s *SCION)elemPathPool(pathType path.Type) path.Path {
	return unfolding s.InitPathPoolExceptOne(pathType) in s.pathPool[pathType]
}

ghost
requires  s.InitPathPoolExceptOne(pathType)
decreases
pure func (s *SCION)pathPoolRawPath(pathType path.Type) path.Path {
	return unfolding s.InitPathPoolExceptOne(pathType) in s.pathPoolRaw
}

// Has the permission for all fields, except those related to the path pools.
// These will come from NonInitPathPool/InitPathPool.
pred (s *SCION) NonInitMem() {
	acc(&s.Version) &&
	acc(&s.TrafficClass) &&
	acc(&s.FlowID) &&
	acc(&s.NextHdr) &&
	acc(&s.HdrLen) &&
	acc(&s.PayloadLen) &&
	acc(&s.PathType) &&
	acc(&s.DstAddrType) &&
	acc(&s.SrcAddrType) &&
	acc(&s.DstIA) &&
	acc(&s.SrcIA) &&
	acc(&s.RawDstAddr) &&
	acc(&s.RawSrcAddr) &&
	acc(&s.Path) &&
	acc(&s.BaseLayer) &&
	s.InitPathPool()
}

pred (s *SCION) Mem(ubuf []byte) {
	acc(&s.Version) &&
	acc(&s.TrafficClass) &&
	acc(&s.FlowID) &&
	acc(&s.NextHdr) &&
	acc(&s.HdrLen) &&
	acc(&s.PayloadLen) &&
	acc(&s.PathType) &&
	acc(&s.DstAddrType, def.ReadL1) && s.DstAddrType.Has3Bits() &&
	acc(&s.SrcAddrType, def.ReadL1) && s.SrcAddrType.Has3Bits() &&
	// len of ubuf:
	0 <= s.HdrLen &&
	0 <= CmnHdrLen + s.AddrHdrLen(nil, true) &&
	s.HdrLen * LineLen <= len(ubuf) &&
	CmnHdrLen + s.AddrHdrLen(nil, true) <= s.HdrLen * LineLen &&
	// end of len of ubuf
	acc(&s.Path) &&
	s.Path != nil &&
	s.Path.Mem(ubuf[CmnHdrLen+s.AddrHdrLen(nil, true) : s.HdrLen*LineLen]) &&
	acc(&s.BaseLayer) &&
	// base layer fields:
	s.Contents === ubuf[:s.HdrLen*LineLen] &&
	s.Payload  === ubuf[s.HdrLen*LineLen:] &&
	// end of base layer fields
	CmnHdrLen <= len(ubuf) &&
	s.HeaderMem(ubuf[CmnHdrLen:]) &&
	// permissions to the rest of the underlying slice:
	slices.AbsSlice_Bytes(ubuf, 0, CmnHdrLen+s.AddrHdrLen(nil, true)) &&
	slices.AbsSlice_Bytes(ubuf, int(s.HdrLen*LineLen), len(ubuf))
	// end of permissions to the rest of the underlying slice
}

pred (s *SCION) HeaderMem(ubuf []byte) {
	acc(&s.DstIA) &&
	acc(&s.SrcIA) &&
	acc(&s.DstAddrType, def.ReadL1) && s.DstAddrType.Has3Bits() &&
	acc(&s.SrcAddrType, def.ReadL1) && s.SrcAddrType.Has3Bits() &&
	s.addrHdrLenAbstractionLeak() <= len(ubuf) &&
	// helper facts to deal with incompletnesses when establising the bounds of s.RawDstAddr and s.RawSrcAddr
	s.AddrHdrLen(nil, true) == s.addrHdrLenAbstractionLeak() &&
	s.AddrHdrLen(nil, true) <= len(ubuf) &&
	0 < s.DstAddrType.Length() && 0 < s.SrcAddrType.Length() &&
	0 < 2*addr.IABytes &&
	2*addr.IABytes < 2*addr.IABytes+s.DstAddrType.Length() &&
	2*addr.IABytes+s.DstAddrType.Length() < 2*addr.IABytes+s.DstAddrType.Length()+s.SrcAddrType.Length() &&
	2*addr.IABytes+s.DstAddrType.Length()+s.SrcAddrType.Length() <= len(ubuf) &&
	// end of helper facts to deal with incompletnesses when establising the bounds of s.RawDstAddr and s.RawSrcAddr
	acc(&s.RawDstAddr) && acc(&s.RawSrcAddr) &&
	// RawDstAddr & RawSrcAddr locations. The memory for these is kept
	// outside of HeaderMem, in the Mem predicate where we just keep
	// access to the entire slice.
	s.RawDstAddr === ubuf[2*addr.IABytes:2*addr.IABytes+s.DstAddrType.Length()] &&
	s.RawSrcAddr === ubuf[2*addr.IABytes+s.DstAddrType.Length():2*addr.IABytes+s.DstAddrType.Length()+s.SrcAddrType.Length()]
}

pred (s *SCION) ChecksumMem() {
	acc(&s.RawSrcAddr) && acc(&s.RawDstAddr) &&
	len(s.RawSrcAddr) % 2 == 0 && len(s.RawDstAddr) % 2 == 0 &&
	acc(&s.SrcIA) && acc(&s.DstIA) &&
	slices.AbsSlice_Bytes(s.RawSrcAddr, 0, len(s.RawSrcAddr)) &&
	slices.AbsSlice_Bytes(s.RawDstAddr, 0, len(s.RawDstAddr))
}

pred (b *BaseLayer) Mem(ghost _ []byte) {
	// TODO: at some point, use the ghost param in the body here
	acc(b) &&
	slices.AbsSlice_Bytes(b.Contents, 0, len(b.Contents)) &&
	slices.AbsSlice_Bytes(b.Payload, 0, len(b.Payload))
}

ghost
pure
decreases
func (a AddrType) Has3Bits() (res bool) {
	return 0 <= a && a <= 7
}

ghost
requires acc(&s.DstAddrType, def.ReadL20) && acc(&s.SrcAddrType, def.ReadL20)
requires s.DstAddrType.Has3Bits() && s.SrcAddrType.Has3Bits()
ensures  0 <= res
decreases
pure
func (s *SCION) addrHdrLenAbstractionLeak() (res int) {
	return 2*addr.IABytes + s.DstAddrType.Length() + s.SrcAddrType.Length()
}

ghost
requires acc(s.Mem(ubuf), _)
ensures  0 <= res
decreases
pure
func (s *SCION) AddrHdrLenNoAbstractionLeak(ubuf []byte) (res int) {
	return unfolding acc(s.Mem(ubuf), _) in (unfolding acc(s.HeaderMem(ubuf[CmnHdrLen:]), _) in (2*addr.IABytes + s.DstAddrType.Length() + s.SrcAddrType.Length()))
}

// Morally ghost
requires acc(p)
ensures  p.NonInitMem()
ensures  r == p
decreases
func FoldOneHopMem(p *onehop.Path) (r *onehop.Path) {
	fold p.NonInitMem()
	return p
}

// Morally ghost
requires acc(p)
ensures  p.NonInitMem()
ensures  r == p
decreases
func FoldRawMem(p *scion.Raw) (r *scion.Raw) {
	fold p.Base.NonInitMem()
	fold p.NonInitMem()
	return p
}

// Morally ghost
requires acc(p)
ensures  p.NonInitMem()
ensures  r == p
decreases
func FoldEpicMem(p *epic.Path) (r *epic.Path) {
	fold p.NonInitMem()
	return p
}

requires def.Uncallable()
func (s *SCION) LayerContents() (res []byte) {
	res = s.Contents
	return res
}

ghost
requires pathType == 0 ==> s.InitPathPool()
requires 0 < pathType  ==> (
	p.NonInitMem() &&
	s.InitPathPoolExceptOne(pathType) &&
	(pathType < s.lenPathPool(pathType) ==> p === s.elemPathPool(pathType)) &&
	(s.lenPathPool(pathType) <= pathType ==> p === s.pathPoolRawPath(pathType)))
ensures  s.InitPathPool()
decreases
func (s *SCION) InitPathPoolExchange(pathType path.Type, p path.Path) {
	// (VerifiedSCION) Gobra cannot establish this atm, but must hold because
	//                 path.Type is defined as an uint8.
	assume 0 <= pathType
	if 0 < pathType {
		unfold s.InitPathPoolExceptOne(pathType)
		fold s.InitPathPool()
	}
}

// gopacket subtyping
*SCION implements gopacket.Layer
*SCION implements gopacket.NetworkLayer
*SCION implements gopacket.SerializableLayer
*SCION implements gopacket.DecodingLayer


ghost
requires typeOf(a) == *net.IPAddr
requires acc(&a.(*net.IPAddr).IP, _)
requires forall i int :: { &a.(*net.IPAddr).IP[i] } 0 <= i && i < len(a.(*net.IPAddr).IP) ==> acc(&a.(*net.IPAddr).IP[i], _)
requires len(a.(*net.IPAddr).IP) == net.IPv6len
pure func isConvertibleToIPv4(a net.Addr) bool {
	return net.isZeros(a.(*net.IPAddr).IP[0:10]) && a.(*net.IPAddr).IP[10] == 255 && a.(*net.IPAddr).IP[11] == 255
}

ghost
requires typeOf(a) == *net.IPAddr
requires acc(&a.(*net.IPAddr).IP, _)
pure func isIPv6(a net.Addr) bool {
	return len(a.(*net.IPAddr).IP) == net.IPv6len
}

ghost
requires typeOf(a) == *net.IPAddr
requires acc(&a.(*net.IPAddr).IP, _)
pure func isIPv4(a net.Addr) bool {
	return len(a.(*net.IPAddr).IP) == net.IPv4len
}

ghost
pure func isIP(a net.Addr) bool {
	return typeOf(a) == *net.IPAddr
}

ghost
pure func isHostSVC(a net.Addr) bool {
	return typeOf(a) == addr.HostSVC
}
