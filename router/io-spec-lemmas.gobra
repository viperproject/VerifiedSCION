// Copyright 2022 ETH Zurich
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// +gobra

package router

import (
	"sync"
	"github.com/scionproto/scion/pkg/slayers/path"
	"github.com/scionproto/scion/pkg/slayers"
	io "verification/io"
	sl "github.com/scionproto/scion/verification/utils/slices"
	. "verification/utils/definitions"
)

ghost
opaque
requires acc(p.scionLayer.Mem(ub), R50)
requires acc(&p.d, R55) && acc(p.d.Mem(), _)
requires acc(&p.ingressID, R55)
decreases
pure func (p *scionPacketProcessor) DstIsLocalIngressID(ub []byte) bool {
	return (unfolding acc(p.scionLayer.Mem(ub), R50) in
		(unfolding acc(p.scionLayer.HeaderMem(ub[slayers.CmnHdrLen:]), R55) in
		p.scionLayer.DstIA) == (unfolding acc(p.d.Mem(), _) in p.d.localIA)) ==> p.ingressID != 0
}

ghost
opaque
requires len(oldPkt.CurrSeg.Future) > 0
ensures len(newPkt.CurrSeg.Future) > 0
ensures  len(newPkt.CurrSeg.Future) == len(oldPkt.CurrSeg.Future)
decreases
pure func AbsUpdateNonConsDirIngressSegID(oldPkt io.IO_pkt2, ingressID option[io.IO_ifs]) (newPkt io.IO_pkt2) {
	return ingressID == none[io.IO_ifs] ? oldPkt : io.IO_pkt2(
			io.IO_Packet2{
				io.establishGuardTraversedseg(oldPkt.CurrSeg, !oldPkt.CurrSeg.ConsDir),
				oldPkt.LeftSeg,
				oldPkt.MidSeg,
				oldPkt.RightSeg})
}

ghost
opaque
requires len(pkt.CurrSeg.Future) > 0
decreases
pure func AbsValidateIngressIDConstraint(pkt io.IO_pkt2, ingressID option[io.IO_ifs]) bool {
	return let currseg := pkt.CurrSeg in
		ingressID != none[io.IO_ifs] ==>
			ingressID == (currseg.ConsDir ? currseg.Future[0].InIF2 : currseg.Future[0].EgIF2)
}

ghost
opaque
requires len(pkt.CurrSeg.Future) > 0
decreases
pure func AbsEgressInterfaceConstraint(pkt io.IO_pkt2, egressID option[io.IO_ifs]) bool {
	return let currseg := pkt.CurrSeg in
			egressID == (currseg.ConsDir ? currseg.Future[0].EgIF2 : currseg.Future[0].InIF2)
}

ghost
opaque
requires dp.Valid()
requires len(pkt.CurrSeg.Future) > 0
decreases
pure func AbsValidateEgressIDConstraint(pkt io.IO_pkt2, enter bool, dp io.DataPlaneSpec) bool {
	return let currseg := pkt.CurrSeg in
		let nextIf := (currseg.ConsDir ? currseg.Future[0].EgIF2 : currseg.Future[0].InIF2) in
		(enter ==> dp.dp2_check_interface_top(currseg.ConsDir, dp.Asid(), currseg.Future[0])) &&
		nextIf != none[io.IO_ifs] &&
		(get(nextIf) in domain(dp.GetNeighborIAs()))
}

ghost
opaque
requires len(oldPkt.CurrSeg.Future) > 0
ensures  len(newPkt.CurrSeg.Future) >= 0
decreases
pure func AbsProcessEgress(oldPkt io.IO_pkt2) (newPkt io.IO_pkt2) {
	return io.IO_pkt2(
			io.IO_Packet2{
				io.establishGuardTraversedsegInc(oldPkt.CurrSeg, oldPkt.CurrSeg.ConsDir),
				oldPkt.LeftSeg,
				oldPkt.MidSeg,
				oldPkt.RightSeg})
}

ghost
opaque
requires oldPkt.LeftSeg != none[io.IO_seg2]
requires len(oldPkt.CurrSeg.Future) == 1
requires len(get(oldPkt.LeftSeg).Future) > 0
ensures  len(newPkt.CurrSeg.Future) > 0
ensures  newPkt.RightSeg != none[io.IO_seg2]
ensures  len(get(newPkt.RightSeg).Past) > 0
decreases
pure func AbsDoXover(oldPkt io.IO_pkt2) (newPkt io.IO_pkt2) {
	return io.IO_pkt2(
			io.IO_Packet2{
				get(oldPkt.LeftSeg),
				oldPkt.MidSeg,
				oldPkt.RightSeg,
				some(io.establishGuardTraversedsegInc(oldPkt.CurrSeg, false))})
}

ghost
opaque
requires  dp.Valid()
requires  len(pkt.CurrSeg.Future) > 0
requires  pkt.RightSeg != none[io.IO_seg2]
requires  len(get(pkt.RightSeg).Past) > 0
decreases
pure func AbsValidateEgressIDConstraintXover(pkt io.IO_pkt2, dp io.DataPlaneSpec) bool {
	return let currseg := pkt.CurrSeg in
		let nextIf := (currseg.ConsDir ? currseg.Future[0].EgIF2 : currseg.Future[0].InIF2) in
		((!get(pkt.RightSeg).ConsDir && pkt.CurrSeg.ConsDir) ==> dp.xover_up2down2_link_type(dp.Asid(), get(pkt.RightSeg).Past[0], pkt.CurrSeg.Future[0])) &&
		((get(pkt.RightSeg).ConsDir == pkt.CurrSeg.ConsDir) ==> dp.xover_core2_link_type(get(pkt.RightSeg).Past[0], pkt.CurrSeg.Future[0], dp.Asid(), get(pkt.RightSeg).ConsDir)) &&
		nextIf != none[io.IO_ifs] &&
		(get(nextIf) in domain(dp.GetNeighborIAs()))
}

// TODO: prove
ghost
requires acc(&p.path, R55) && acc(p.path.Mem(ubPath), R55)
requires unfolding acc(p.path.Mem(ubPath), R55) in p.path.Base.IsXoverSpec()
requires dp.Valid()
requires acc(sl.AbsSlice_Bytes(ub, 0, len(ub)), R55)
requires validPktMetaHdr(ub)
requires absPkt(dp, ub) != none[io.IO_pkt2]
requires 0 <= start && start <= end && end <= len(ubPath) && len(ubPath) <= len(ub)
preserves ub[start:end] === ubPath
ensures acc(&p.path, R9) && acc(p.path.Mem(ub), R9)
ensures dp.Valid()
ensures acc(sl.AbsSlice_Bytes(ub, 0, len(ub)), R55)
ensures validPktMetaHdr(ub)
ensures absPkt(dp, ub) != none[io.IO_pkt2]
ensures get(absPkt(dp, ub)).LeftSeg != none[io.IO_seg2]
ensures len(get(absPkt(dp, ub)).CurrSeg.Future) == 1
decreases
func (p* scionPacketProcessor) XoverLemma(ub []byte, ubPath []byte, start int, end int, dp io.DataPlaneSpec)


ghost
opaque
requires dp.Valid()
requires len(pkt.CurrSeg.Future) > 0
decreases
pure func AbsVerifyCurrentMACConstraint(pkt io.IO_pkt2, dp io.DataPlaneSpec) bool {
	return let currseg := pkt.CurrSeg in
		let d := currseg.ConsDir in
		let ts := currseg.AInfo in
		let hf := currseg.Future[0] in
		let uinfo := currseg.UInfo in
		dp.hf_valid(d, ts, uinfo, hf)
}

ghost
requires dp.Valid()
requires ingressID != none[io.IO_ifs]
requires egressID == none[io.IO_ifs]
requires len(oldPkt.CurrSeg.Future) > 0
requires ElemWitness(ioSharedArg.IBufY, ingressID, oldPkt)
requires newPkt == AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)
requires AbsValidateIngressIDConstraint(oldPkt, ingressID)
requires AbsVerifyCurrentMACConstraint(newPkt, dp)
preserves acc(ioLock.LockP(), _) && ioLock.LockInv() == SharedInv!< dp, ioSharedArg !>;
ensures dp.Valid()
ensures ElemWitness(ioSharedArg.OBufY, egressID, newPkt)
decreases
func InternalEnterEvent(oldPkt io.IO_pkt2, ingressID option[io.IO_ifs], newPkt io.IO_pkt2, egressID option[io.IO_ifs], ioLock *sync.Mutex, ioSharedArg SharedArg, dp io.DataPlaneSpec) {
	reveal AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)
	reveal AbsValidateIngressIDConstraint(oldPkt, ingressID)
	reveal AbsVerifyCurrentMACConstraint(newPkt, dp)
	AtomicEnter(oldPkt, ingressID, newPkt, egressID, ioLock, ioSharedArg, dp)
}

ghost
requires dp.Valid()
requires len(oldPkt.CurrSeg.Future) > 0
requires ElemWitness(ioSharedArg.IBufY, ingressID, oldPkt)
requires AbsValidateIngressIDConstraint(oldPkt, ingressID)
requires AbsVerifyCurrentMACConstraint(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID), dp)
requires AbsEgressInterfaceConstraint(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID), egressID)
requires AbsValidateEgressIDConstraint(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID), (ingressID != none[io.IO_ifs]), dp)
requires newPkt == AbsProcessEgress(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID))
preserves acc(ioLock.LockP(), _) && ioLock.LockInv() == SharedInv!< dp, ioSharedArg !>;
ensures dp.Valid()
ensures ElemWitness(ioSharedArg.OBufY, egressID, newPkt)
decreases
func ExternalEvent(oldPkt io.IO_pkt2, ingressID option[io.IO_ifs], newPkt io.IO_pkt2, egressID option[io.IO_ifs], ioLock *sync.Mutex, ioSharedArg SharedArg, dp io.DataPlaneSpec) {
	reveal dp.Valid()
	nextPkt := reveal AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)
	reveal AbsValidateIngressIDConstraint(oldPkt, ingressID)
	reveal AbsVerifyCurrentMACConstraint(nextPkt, dp)
	reveal AbsEgressInterfaceConstraint(nextPkt, egressID)
	reveal AbsValidateEgressIDConstraint(nextPkt, (ingressID != none[io.IO_ifs]), dp)
	reveal AbsProcessEgress(nextPkt)
	if(ingressID == none[io.IO_ifs]){
		AtomicExit(oldPkt, ingressID, newPkt, egressID, ioLock, ioSharedArg, dp)
	} else {
		AtomicEnter(oldPkt, ingressID, newPkt, egressID, ioLock, ioSharedArg, dp)
	}
}


ghost
requires dp.Valid()
requires len(oldPkt.CurrSeg.Future) > 0
requires ElemWitness(ioSharedArg.IBufY, ingressID, oldPkt)
requires AbsValidateIngressIDConstraint(oldPkt, ingressID)
requires AbsVerifyCurrentMACConstraint(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID), dp)
requires AbsEgressInterfaceConstraint(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID), egressID)
requires AbsValidateEgressIDConstraint(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID), (ingressID != none[io.IO_ifs]), dp)
requires newPkt == AbsProcessEgress(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID))
preserves acc(ioLock.LockP(), _) && ioLock.LockInv() == SharedInv!< dp, ioSharedArg !>;
ensures dp.Valid()
ensures ElemWitness(ioSharedArg.OBufY, egressID, newPkt)
decreases
func XoverEvent(oldPkt io.IO_pkt2, ingressID option[io.IO_ifs], newPkt io.IO_pkt2, egressID option[io.IO_ifs], ioLock *sync.Mutex, ioSharedArg SharedArg, dp io.DataPlaneSpec) {
	assume (!oldPkt.CurrSeg.ConsDir && newPkt.CurrSeg.ConsDir) || (oldPkt.CurrSeg.ConsDir == newPkt.CurrSeg.ConsDir)
	reveal dp.Valid()
	nextPkt := reveal AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)
	reveal AbsValidateIngressIDConstraint(oldPkt, ingressID)
	reveal AbsVerifyCurrentMACConstraint(nextPkt, dp)
	reveal AbsEgressInterfaceConstraint(nextPkt, egressID)
	reveal AbsValidateEgressIDConstraint(nextPkt, (ingressID != none[io.IO_ifs]), dp)
	reveal AbsProcessEgress(nextPkt)
	if(!oldPkt.CurrSeg.ConsDir && nextPkt.CurrSeg.ConsDir) {
		AtomicXoverUp2Down(oldPkt, ingressID, newPkt, egressID, ioLock, ioSharedArg, dp)
	} else {
		// TODO: How to deal with core?
		assume dp.Asid() in dp.Core()
		AtomicXoverCore(oldPkt, ingressID, newPkt, egressID, ioLock, ioSharedArg, dp)
	}
}
