// Copyright 2022 ETH Zurich
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// +gobra

package router

import (
	"github.com/scionproto/scion/pkg/slayers/path"
	"github.com/scionproto/scion/pkg/slayers/path/scion"
	"github.com/scionproto/scion/pkg/slayers"
	. "verification/utils/definitions"
	io "verification/io"
	gsync "verification/utils/ghost_sync"
	sl "verification/utils/slices"
)

ghost
requires pkt.PathNotFullyTraversed()
decreases
pure func CurrSegIO_ifs(pkt io.Pkt, dir bool) option[io.Ifs] {
	return let currseg := pkt.CurrSeg in
		(currseg.ConsDir == dir ? currseg.Future[0].InIF2 : currseg.Future[0].EgIF2)
}

ghost
opaque
requires oldPkt.PathNotFullyTraversed()
ensures  newPkt.PathNotFullyTraversed()
ensures  len(newPkt.CurrSeg.Future) == len(oldPkt.CurrSeg.Future)
decreases
pure func AbsUpdateNonConsDirIngressSegID(oldPkt io.Pkt, ingressID option[io.Ifs]) (newPkt io.Pkt) {
	return ingressID == none[io.Ifs] ? oldPkt : io.Pkt {
		io.establishGuardTraversedseg(oldPkt.CurrSeg, !oldPkt.CurrSeg.ConsDir),
		oldPkt.LeftSeg,
		oldPkt.MidSeg,
		oldPkt.RightSeg,
	}
}

ghost
opaque
requires pkt.PathNotFullyTraversed()
decreases
pure func AbsValidateIngressIDConstraint(pkt io.Pkt, ingressID option[io.Ifs]) bool {
	return let currseg := pkt.CurrSeg in
		ingressID != none[io.Ifs] ==>
			ingressID == CurrSegIO_ifs(pkt, true)
}

ghost
opaque
requires pkt.RightSeg != none[io.Seg]
requires len(get(pkt.RightSeg).Past) > 0
decreases
pure func AbsValidateIngressIDConstraintXover(pkt io.Pkt, ingressID option[io.Ifs]) bool {
	return let rightseg := get(pkt.RightSeg) in
		ingressID != none[io.Ifs] ==>
			ingressID == (rightseg.ConsDir ? rightseg.Past[0].InIF2 : rightseg.Past[0].EgIF2)
}

ghost
opaque
requires pkt.PathNotFullyTraversed()
decreases
pure func AbsEgressInterfaceConstraint(pkt io.Pkt, egressID option[io.Ifs]) bool {
	return let currseg := pkt.CurrSeg in
		egressID == CurrSegIO_ifs(pkt, false)
}

ghost
opaque
requires dp.Valid()
requires pkt.PathNotFullyTraversed()
decreases
pure func AbsValidateEgressIDConstraint(pkt io.Pkt, enter bool, dp io.DataPlaneSpec) bool {
	return let currseg := pkt.CurrSeg in
		(enter ==> dp.dp2_check_interface_top(currseg.ConsDir, dp.Asid(), currseg.Future[0]))
}

ghost
opaque
requires oldPkt.PathNotFullyTraversed()
ensures  len(newPkt.CurrSeg.Future) >= 0
decreases
pure func AbsProcessEgress(oldPkt io.Pkt) (newPkt io.Pkt) {
	return io.Pkt {
		io.establishGuardTraversedsegInc(oldPkt.CurrSeg, oldPkt.CurrSeg.ConsDir),
		oldPkt.LeftSeg,
		oldPkt.MidSeg,
		oldPkt.RightSeg,
	}
}

ghost
opaque
requires oldPkt.LeftSeg != none[io.Seg]
requires len(oldPkt.CurrSeg.Future) == 1
requires len(get(oldPkt.LeftSeg).Future) > 0
requires len(get(oldPkt.LeftSeg).History) == 0
ensures  newPkt.PathNotFullyTraversed()
ensures  newPkt.RightSeg != none[io.Seg]
ensures  len(get(newPkt.RightSeg).Past) > 0
decreases
pure func AbsDoXover(oldPkt io.Pkt) (newPkt io.Pkt) {
	return io.Pkt {
		get(oldPkt.LeftSeg),
		oldPkt.MidSeg,
		oldPkt.RightSeg,
		some(io.establishGuardTraversedsegInc(oldPkt.CurrSeg, false)),
	}
}

ghost
opaque
requires  dp.Valid()
requires  pkt.PathNotFullyTraversed()
requires  pkt.RightSeg != none[io.Seg]
requires  len(get(pkt.RightSeg).Past) > 0
decreases
pure func AbsValidateEgressIDConstraintXover(pkt io.Pkt, dp io.DataPlaneSpec) bool {
	return let currseg := pkt.CurrSeg in
		let rightseg := get(pkt.RightSeg) in
		dp.xover2_link_type_dir(dp.Asid(), rightseg.ConsDir, rightseg.Past[0],
			currseg.ConsDir, currseg.Future[0])
}

ghost
opaque
requires pkt.PathNotFullyTraversed()
decreases
pure func AbsVerifyCurrentMACConstraint(pkt io.Pkt, dp io.DataPlaneSpec) bool {
	return let currseg := pkt.CurrSeg in
		let d := currseg.ConsDir in
		let ts := currseg.AInfo in
		let hf := currseg.Future[0] in
		let uinfo := currseg.UInfo in
		dp.hf_valid(d, ts.V, uinfo, hf)
}

// This executes the IO enter event whenever a pkt was received
// from a different AS (ingressID != none[io.Ifs])
// and will be forwarded to another border router within the AS (egressID == none[io.Ifs])
ghost
requires  dp.Valid()
requires  ingressID != none[io.Ifs]
requires  egressID == none[io.Ifs]
requires  oldPkt.PathNotFullyTraversed()
requires  ElemWitness(ioSharedArg.IBufY, ingressID, oldPkt)
requires  newPkt == AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)
requires  AbsValidateIngressIDConstraint(oldPkt, ingressID)
requires  AbsVerifyCurrentMACConstraint(newPkt, dp)
requires  len(newPkt.CurrSeg.Future) == 1 || AbsValidateEgressIDConstraint(newPkt, true, dp)
preserves acc(ioLock.LockP(), _)
preserves ioLock.LockInv() == SharedInv!< dp, ioSharedArg !>
ensures   ElemWitness(ioSharedArg.OBufY, egressID, newPkt)
decreases
func InternalEnterEvent(oldPkt io.Pkt, ingressID option[io.Ifs], newPkt io.Pkt, egressID option[io.Ifs], ioLock gpointer[gsync.GhostMutex], ioSharedArg SharedArg, dp io.DataPlaneSpec) {
	reveal AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)
	reveal AbsValidateIngressIDConstraint(oldPkt, ingressID)
	reveal AbsVerifyCurrentMACConstraint(newPkt, dp)
	if(len(newPkt.CurrSeg.Future) != 1) {
		reveal AbsValidateEgressIDConstraint(newPkt, true, dp)
	}
	AtomicEnter(oldPkt, ingressID, newPkt, egressID, ioLock, ioSharedArg, dp)
}

// Either this executes the IO enter event whenever a pkt was received
// from a different AS (ingressID != none[io.Ifs])
// and will leave the AS (egressID != none[io.Ifs]) or
// it executes the IO exit event whenever a pkt was received from
// within the AS (ingressID == none[io.Ifs])
// and will leave the AS (egressID != none[io.Ifs])
ghost
requires  dp.Valid()
requires  egressID != none[io.Ifs]
requires  get(egressID) in domain(dp.GetNeighborIAs())
requires  oldPkt.PathNotFullyTraversed()
requires  ElemWitness(ioSharedArg.IBufY, ingressID, oldPkt)
requires  AbsValidateIngressIDConstraint(oldPkt, ingressID)
requires  AbsVerifyCurrentMACConstraint(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID), dp)
requires  AbsValidateEgressIDConstraint(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID), (ingressID != none[io.Ifs]), dp)
requires  AbsEgressInterfaceConstraint(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID), egressID)
requires  newPkt == AbsProcessEgress(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID))
preserves acc(ioLock.LockP(), _)
preserves ioLock.LockInv() == SharedInv!< dp, ioSharedArg !>
ensures   ElemWitness(ioSharedArg.OBufY, egressID, newPkt)
decreases
func ExternalEnterOrExitEvent(oldPkt io.Pkt, ingressID option[io.Ifs], newPkt io.Pkt, egressID option[io.Ifs], ioLock gpointer[gsync.GhostMutex], ioSharedArg SharedArg, dp io.DataPlaneSpec) {
	reveal dp.Valid()
	nextPkt := reveal AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)
	reveal AbsValidateIngressIDConstraint(oldPkt, ingressID)
	reveal AbsVerifyCurrentMACConstraint(nextPkt, dp)
	reveal AbsEgressInterfaceConstraint(nextPkt, egressID)
	reveal AbsValidateEgressIDConstraint(nextPkt, (ingressID != none[io.Ifs]), dp)
	reveal AbsProcessEgress(nextPkt)
	if(ingressID == none[io.Ifs]){
		AtomicExit(oldPkt, ingressID, newPkt, egressID, ioLock, ioSharedArg, dp)
	} else {
		AtomicEnter(oldPkt, ingressID, newPkt, egressID, ioLock, ioSharedArg, dp)
	}
}

// This executes the IO xover event whenever a pkt was received
// from a different AS (ingressID != none[io.Ifs])
// and a segment switch was performed.
ghost
requires  dp.Valid()
requires  ingressID != none[io.Ifs]
requires  oldPkt.PathNotFullyTraversed()
requires  ElemWitness(ioSharedArg.IBufY, ingressID, oldPkt)
requires  AbsValidateIngressIDConstraint(oldPkt, ingressID)
requires  AbsVerifyCurrentMACConstraint(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID), dp)
requires  len(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID).CurrSeg.Future) == 1
requires  AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID).LeftSeg != none[io.Seg]
requires  len(get(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID).LeftSeg).Future) > 0
requires  len(get(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID).LeftSeg).History) == 0
requires  AbsVerifyCurrentMACConstraint(AbsDoXover(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)), dp)
requires  AbsValidateEgressIDConstraintXover(AbsDoXover(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)), dp)
requires  egressID != none[io.Ifs] ==> get(egressID) in domain(dp.GetNeighborIAs())
requires  egressID != none[io.Ifs] ==> AbsEgressInterfaceConstraint(AbsDoXover(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)), egressID)
requires  egressID == none[io.Ifs] ==>
	newPkt == AbsDoXover(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID))
requires  egressID != none[io.Ifs] ==>
	newPkt == AbsProcessEgress(AbsDoXover(AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)))
preserves acc(ioLock.LockP(), _)
preserves ioLock.LockInv() == SharedInv!< dp, ioSharedArg !>
ensures   ElemWitness(ioSharedArg.OBufY, egressID, newPkt)
decreases
func XoverEvent(oldPkt io.Pkt, ingressID option[io.Ifs], newPkt io.Pkt, egressID option[io.Ifs], ioLock gpointer[gsync.GhostMutex], ioSharedArg SharedArg, dp io.DataPlaneSpec) {
	reveal dp.Valid()
	intermediatePkt1 := reveal AbsUpdateNonConsDirIngressSegID(oldPkt, ingressID)
	intermediatePkt2 := reveal AbsDoXover(intermediatePkt1)
	reveal AbsValidateIngressIDConstraint(oldPkt, ingressID)
	reveal AbsVerifyCurrentMACConstraint(intermediatePkt1, dp)
	reveal AbsVerifyCurrentMACConstraint(intermediatePkt2, dp)
	reveal AbsValidateEgressIDConstraintXover(intermediatePkt2, dp)
	if(egressID != none[io.Ifs]){
		reveal AbsEgressInterfaceConstraint(intermediatePkt2, egressID)
		reveal AbsProcessEgress(intermediatePkt2)
	}
	AtomicXover(oldPkt, ingressID, newPkt, egressID, ioLock, ioSharedArg, dp)
}
