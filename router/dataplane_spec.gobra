// Copyright 2022 ETH Zurich
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// +gobra

package router

import (
	"net"
	"hash"
	sl "github.com/scionproto/scion/verification/utils/slices"
	"github.com/scionproto/scion/pkg/scrypto"
	"github.com/scionproto/scion/pkg/addr"
	"github.com/scionproto/scion/pkg/slayers/path/scion"
)

// TODO: maybe change interpretation of Mutex depending on whether the
// dataplane is running or not. This is because, when Run is called and
// d.running is set to true, the permissions to some of these fields is transferred
// to the read closure, and thus, we cannot transfer it back on the call to unlock
// at the end of run
pred MutexInvariant(d *DataPlane) {
	// access to the field 'mtx' ommited
	acc(&d.external,          1/2) &&
	acc(&d.linkTypes,         1/2) &&
	acc(&d.neighborIAs,       1/2) &&
	acc(&d.internal,          1/2) &&
	acc(&d.internalIP,        1/2) &&
	acc(&d.internalNextHops,  1/2) &&
	acc(&d.svc,               1/2) &&
	acc(&d.macFactory,        1/2) &&
	acc(&d.bfdSessions,       1/2) &&
	acc(&d.localIA,           1/2) &&
	acc(&d.running,           1/2) &&
	acc(&d.Metrics,           1/2) &&
	acc(&d.forwardingMetrics, 1/2) &&
	acc(&d.key,               1/2) &&
	(d.external    != nil       ==> AccBatchConn(d.external))           &&
	(d.linkTypes   != nil       ==> acc(d.linkTypes, 1/2))              &&
	(d.neighborIAs != nil       ==> acc(d.neighborIAs, 1/2))            &&
	(d.internal != nil          ==> d.internal.Mem())                   &&
	(d.internalIP != nil        ==> d.internalIP.Mem())                 &&
	(d.internalNextHops != nil  ==> AccAddr(d.internalNextHops))        &&
	(d.svc != nil               ==> acc(d.svc.Mem(), _))                &&
	(d.macFactory != nil        ==> acc(d.key, 1/2))                    &&
	(d.macFactory != nil        ==> acc(sl.AbsSlice_Bytes(*d.key, 0, len(*d.key)), _)) &&
	(d.macFactory != nil        ==> scrypto.ValidKeyForHash(*d.key))    &&
	(d.macFactory != nil        ==> d.macFactory implements MacFactorySpec{d.key}) &&
	(d.bfdSessions != nil       ==> AccBfdSession(d.bfdSessions))       &&
	(d.Metrics != nil           ==> acc(d.Metrics.Mem(), _))            &&
	// The following permissions are enough to call all methods needed in fields
	// of forwardingMetrics
	(d.forwardingMetrics != nil ==> AccForwardingMetrics(d.forwardingMetrics))
}

// TODO: reorganize permissions consistently

// TODO: use lower case for these predicates' names?
// TODO: drop wildcards here
pred AccAddr(addrs map[uint16]*net.UDPAddr) {
	acc(addrs, 1/2) &&
	forall a *net.UDPAddr :: { a in range(addrs) } a in range(addrs) ==> acc(a.Mem(), _)
}

pred AccBatchConn(batchConns map[uint16]BatchConn) {
	acc(batchConns, 1/2) &&
	forall b BatchConn :: b in range(batchConns) ==> b.Mem()
}

// TODO: drop wildcards here
pred AccBfdSession(bfdSessions map[uint16]bfdSession) {
	acc(bfdSessions, 1/2) &&
	(forall bfd bfdSession :: { bfd in range(bfdSessions) } bfd in range(bfdSessions) ==> (bfd != nil && acc(bfd.Mem(), _)))
}

// TODO: drop wildcards here
pred AccForwardingMetrics(metrics map[uint16]forwardingMetrics) {
	acc(metrics, 1/2) &&
	forall id uint16 :: { metrics[id] } id in domain(metrics) ==> acc(forwardingMetricsMem(metrics[id], id), _)
}

pred forwardingMetricsMem(v forwardingMetrics, ignoredForInjectivity uint16) {
	v.InputBytesTotal.Mem()      &&
	v.OutputBytesTotal.Mem()     &&
	v.InputPacketsTotal.Mem()    &&
	v.OutputPacketsTotal.Mem()   &&
	v.DroppedPacketsTotal.Mem()
}

pred forwardingMetricsNonInjectiveMem(v forwardingMetrics) {
	v.InputBytesTotal.Mem()      &&
	v.OutputBytesTotal.Mem()     &&
	v.InputPacketsTotal.Mem()    &&
	v.OutputPacketsTotal.Mem()   &&
	v.DroppedPacketsTotal.Mem()
}

ghost
requires  acc(forwardingMetricsNonInjectiveMem(v), _)
ensures   acc(forwardingMetricsMem(v, id), _)
decreases
func liftForwardingMetricsNonInjectiveMem(v forwardingMetrics, id uint16) {
	unfold acc(forwardingMetricsNonInjectiveMem(v), _)
	fold acc(forwardingMetricsMem(v, id), _)
}

pred (p *scionPacketProcessor) initMem() {
	acc(&p.d) &&
	acc(&p.ingressID) &&
	acc(&p.buffer) &&
	acc(&p.mac) &&
	acc(p.scionLayer.NonInitMem()) &&
	p.scionLayer.PathPoolInitializedNonInitMem() &&
	acc(&p.hbhLayer) &&
	acc(&p.e2eLayer) &&
	acc(&p.lastLayer) &&
	acc(&p.path) &&
	acc(&p.hopField) &&
	acc(&p.infoField) &&
	acc(&p.segmentChange) &&
	acc(&p.cachedMac) &&
	acc(&p.macBuffers) &&
	acc(&p.bfdLayer)
}

requires acc(key, _) && acc(sl.AbsSlice_Bytes(*key, 0, len(*key)), _)
requires scrypto.ValidKeyForHash(*key)
ensures  acc(key, _) && acc(sl.AbsSlice_Bytes(*key, 0, len(*key)), _)
ensures  res.Mem()
decreases
func MacFactorySpec(ghost key *[]byte) (res hash.Hash)

// useful to deal with incompletnesses
pred hideLocalIA(p *addr.IA) {
	acc(p)
}

pred (err scmpError) ErrorMem() {
	err.Cause != nil ==> err.Cause.ErrorMem()
}

// Currently assumed, as Gobra cannot currently prove termination
// of the code below
ghost
trusted
pure
decreases
func (err scmpError) IsDuplicableMem() bool {
	return err != nil? err.cause.IsDuplicableMem() : true
}

// Currently assumed, as Gobra cannot currently prove termination
// of the code below
ghost
trusted
preserves err.ErrorMem()
ensures   err.IsDuplicableMem() ==> err.ErrorMem()
decreases
func (err scmpError) Duplicate() {
	if err.IsDuplicableMem() {
		unfold err.ErrorMem()
		err.cause.Duplicate()
		fold err.ErrorMem()
	}
}

scmpError implements error

type offsetPair struct {
	start int
	end int
	isNil bool
}

// Helper functions for prepareSCMP

ghost
requires acc(MutexInvariant(d), _)
requires unfolding acc(MutexInvariant(d), _) in d.external != nil
ensures acc(&d.external, _) && acc(AccBatchConn(d.external), _)
func (d *DataPlane) accToExternalAndBatchConn () {
	unfold acc(MutexInvariant(d), _)
}

ghost
pure
requires 0 <= n
ensures  len(res) == n
ensures  forall i int :: {res[i]} 0 <= i && i < len(res) ==> res[i] == offsetPair{}
decreases
func newOffsetPair(n int) (res seq[offsetPair])

/**** Acessor methods to avoid unfolding the Mem predicate of the dataplane so much ****/
ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.internalNextHops, _)
ensures  d.internalNextHops != nil  ==> acc(AccAddr(d.internalNextHops), _)
decreases
func (d *DataPlane) getInternalNextHops() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.external, _) && (d.external != nil ==> acc(AccBatchConn(d.external), _))
decreases
func (d *DataPlane) getExternalMem() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.linkTypes, _) && (d.linkTypes != nil ==> acc(d.linkTypes, _))
decreases
func (d *DataPlane) getLinkTypesMem() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.localIA, _)
decreases
func (d *DataPlane) getLocalIA() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.neighborIAs, _) && (d.neighborIAs != nil ==> acc(d.neighborIAs, _))
decreases
func (d *DataPlane) getNeighborIAs() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.svc, _) && (d.svc != nil ==> acc(d.svc.Mem(), _))
decreases
func (d *DataPlane) getSvcMem() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.bfdSessions, _) && (d.bfdSessions != nil ==> acc(AccBfdSession(d.bfdSessions), _))
decreases
func (d *DataPlane) getBfdSessionsMem() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.internal, _) && (d.internal != nil ==> acc(d.internal.Mem(), _))
decreases
func (d *DataPlane) getInternal() {
	unfold acc(MutexInvariant!<d!>(), _)
}

requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.macFactory, _)
decreases
func (d *DataPlane) getMacFactoryMem() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
requires acc(&d.macFactory, _) && d.macFactory != nil
ensures  acc(&d.macFactory, _) && acc(&d.key, _) && acc(d.key, _)
ensures  acc(sl.AbsSlice_Bytes(*d.key, 0, len(*d.key)), _)
ensures  scrypto.ValidKeyForHash(*d.key)
ensures  d.macFactory implements MacFactorySpec{d.key}
decreases
func (d *DataPlane) getNewPacketProcessorFootprint() {
    unfold acc(MutexInvariant!<d!>(), _)
}

/**** End of acessor methods to avoid unfolding the Mem predicate of the dataplane so much ****/

/**** Post-init invariants ****/

// unsupportedPathType is duplicable: we can always establish its invariant
ghost
ensures unsupportedPathType.ErrorMem()
decreases _
func establishMemUnsupportedPathType()

// malformedPath is duplicable: we can always establish its invariant
ghost
ensures malformedPath != nil
ensures malformedPath.ErrorMem()
decreases _
func establishMemMalformedPath()

// unsupportedPathTypeNextHeader is duplicable: we can always establish its invariant
ghost
ensures unsupportedPathTypeNextHeader.ErrorMem()
decreases _
func establishMemUnsupportedPathTypeNextHeader()

// noBFDSessionConfigured is duplicable: we can always establish its invariant
ghost
ensures noBFDSessionConfigured.ErrorMem()
decreases _
func establishMemNoBFDSessionConfigured()

// noBFDSessionFound is duplicable: we can always establish its invariant
ghost
ensures noBFDSessionFound.ErrorMem()
decreases _
func establishMemNoBFDSessionFound()

// invalidSrdAddrForTransit is duplicable: we can always establish its invariant
ghost
ensures invalidSrcAddrForTransit.ErrorMem()
decreases _
func establishInvalidSrcAddrForTransit()

// noSVCBackend is duplicable: we can always establish its invariant
ghost
ensures noSVCBackend.ErrorMem()
decreases _
func establishNoSVCBackend()

// cannotRoute is duplicable: we can always establish its invariant after init
ghost
ensures cannotRoute.ErrorMem()
decreases _
func establishCannotRoute()

/**** End of post-init invariants ****/

/** Start of closure specs for the Run method **/
requires true
func readClosureSpec(ingressID uint16, rd BatchConn)

requires true
func closureSpec1(ifID uint16, c bfdSession)

requires true
func closureSpec2(i uint16, c BatchConn)

requires true
func closureSpec3(c BatchConn)
/** End of closure specs for the Run method **/
