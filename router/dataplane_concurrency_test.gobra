package router

import (
	"sync"
	io "verification/io"
	sl "github.com/scionproto/scion/verification/utils/slices"
)

ghost
decreases
pure func ifsToIO_ifs(ifs uint16) option[io.IO_ifs]{
	return ifs == 0 ? none[io.IO_ifs] : some(io.IO_ifs(ifs))
}

ghost
decreases
requires acc(sl.AbsSlice_Bytes(ub, 0, len(ub)), _)
requires dp.Valid()
ensures e.isIO_val_Pkt2 || e.isIO_val_Unsupported
ensures e.isIO_val_Pkt2 ==> len(e.IO_val_Pkt2_2.CurrSeg.Future) > 0
ensures e.isIO_val_Pkt2 ==> e.IO_val_Pkt2_2.CurrSeg.Future[0].extr_asid() == dp.Asid()
pure func IO_val_Abs(ub Pkt, ghost dp io.DataPlaneSpec) (ghost e io.IO_val)

ghost
decreases
ensures ElemWitness(ioSharedArg, k, e)
func AssumeElemWitness(ghost ioSharedArg ElemRA, ghost k Key, ghost e Elem)

type Pkt []byte

decreases
requires Prophecy(prophecyM)
requires io.token(t) && MultiReadBio(t, prophecyM)
requires forall i int :: {&buf[i]} 0 <= i && i < len(buf) ==> acc(&buf[i])
preserves dp.Valid()
ensures  err != 0 ==> prophecyM == 0
ensures  err == 0 ==> prophecyM == n
ensures  err == 0 ==> 0 <= n && n <= len(buf)
ensures  io.token(old(MultiReadBioNext(t, prophecyM))) && old(MultiReadBioCorrectIfs(t, prophecyM, ifsToIO_ifs(c)))
ensures  forall i int :: {&buf[i]} 0 <= i && i < len(buf) ==> acc(&buf[i])
ensures  err == 0 ==> forall i int :: {&buf[i]} 0 <= i && i < n ==>
	acc(sl.AbsSlice_Bytes(buf[i], 0, len(buf[i])), _) && IO_val_Abs(buf[i], dp) == old(MultiReadBioIO_val(t, n)[i])
func BatchRecv(c uint16, buf []Pkt, ghost prophecyM int, ghost t io.Place, ghost dp io.DataPlaneSpec) (n int, err int)


ghost
decreases
requires io.token(place) && io.CBioIO_bio3s_send(place, ioAbsPkts)
ensures  err != 0 ==> io.token(place) && io.CBioIO_bio3s_send(place, ioAbsPkts) && old(io.dp3s_iospec_bio3s_send_T(place, ioAbsPkts)) == io.dp3s_iospec_bio3s_send_T(place, ioAbsPkts)
ensures  err == 0 ==> io.token(old(io.dp3s_iospec_bio3s_send_T(place, ioAbsPkts)))
func BatchSend(ghost place io.Place, ghost ioAbsPkts io.IO_val) (err int)

//----------------------------------------------------------------------//

requires dp.Valid()
requires io.token(place) && dp.dp3s_iospec_ordered(s, place)
func rc (ingressID uint16, ghost place io.Place, ghost s io.IO_dp3s_state_local, ghost dp io.DataPlaneSpec) {
  ghost ioLock, ioSharedArg := InitSharedInv(dp, place, s)
  ghost from := ifsToIO_ifs(ingressID)
  buf := make([]Pkt, 1000)

  invariant dp.Valid()
  invariant ifsToIO_ifs(ingressID) == from
  invariant acc(ioLock.LockP(), _) && ioLock.LockInv() == SharedInv!< dp, ioSharedArg !>;
  invariant forall i int :: {&buf[i]} 0 <= i && i < len(buf) ==> acc(&buf[i])
  for true {
	// multi recv
	ghost ioLock.Lock()
	unfold SharedInv!< dp, ioSharedArg !>()

	ghost t, s := *ioSharedArg.Place, *ioSharedArg.State
	ghost numberOfReceivedPacketsProphecy := AllocProphecy()
	ExtractMultiReadBio(dp, t, numberOfReceivedPacketsProphecy, s)
	MultiUpdateElemWitness(t, numberOfReceivedPacketsProphecy, from, s, ioSharedArg)
	ghost es_val := MultiReadBioIO_val(t,numberOfReceivedPacketsProphecy)

	ghost sN := MultiReadBioUpd(t, numberOfReceivedPacketsProphecy, s)
	ghost tN := MultiReadBioNext(t, numberOfReceivedPacketsProphecy)
	assert dp.dp3s_iospec_ordered(sN, tN)
	pkts, err := BatchRecv(ingressID, buf, numberOfReceivedPacketsProphecy, t, dp)
	ghost *ioSharedArg.State = sN
	ghost *ioSharedArg.Place = tN
	MultiElemWitnessConv(ioSharedArg.IBufY, from, es_val)
	//assert err == 0 ==> forall i int :: {es_val[i]} 0 <= i && i < pkts ==> IO_val_Abs(buf[i]) == es_val[i]
	//assert err == 0 ==> MultiElemWitnessWithIndex(ioSharedArg.IBufY, from, es_val, 0)
	fold SharedInv!< dp, ioSharedArg !>()
	ioLock.Unlock()
	//end of recv
	if err != 0{
		continue
	}

	if pkts == 0{
		continue
	}

    invariant dp.Valid()
	invariant 0 <= i0 && i0 <= pkts
	invariant pkts <= len(buf)
	invariant ifsToIO_ifs(ingressID) == from
	invariant acc(ioLock.LockP(), _) && ioLock.LockInv() == SharedInv!< dp, ioSharedArg !>;
	invariant forall i int :: {&buf[i]} 0 <= i && i < len(buf) ==> acc(&buf[i])
	invariant forall i int :: {&buf[i]} i0 <= i && i < pkts ==>
		acc(sl.AbsSlice_Bytes(buf[i], 0, len(buf[i])), _) && IO_val_Abs(buf[i], dp) == es_val[i]
	invariant MultiElemWitnessWithIndex(ioSharedArg.IBufY, from, es_val, i0)
	decreases pkts - i0
	for i0 := 0; i0 < pkts; i0++ {
	  unfold MultiElemWitnessWithIndex(ioSharedArg.IBufY, from, es_val, i0)
	  //assume IO_val_Abs(ub).isIO_val_Pkt2
	  assert acc(&buf[i0])
	  assert acc(sl.AbsSlice_Bytes(buf[i0], 0, len(buf[i0])), _)
	  ghost newAbsPkt := processPkt(buf[i0], ingressID, ioLock, ioSharedArg, dp)
	  assume false
	  //send
	  ghost ioLock.Lock()
	  unfold SharedInv!< dp, ioSharedArg !>()

	  t, s := *ioSharedArg.Place, *ioSharedArg.State
	  ghost if(newAbsPkt.isIO_val_Pkt2) {
	  ApplyElemWitness(s.obuf, ioSharedArg.OBufY, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)
	  assert newAbsPkt.IO_val_Pkt2_2 in AsSet(s.obuf[newAbsPkt.IO_val_Pkt2_1])
	  assert dp.dp3s_iospec_bio3s_send_guard(s, t, newAbsPkt)
	 }

	  unfold dp.dp3s_iospec_ordered(s, t)
	  unfold dp.dp3s_iospec_bio3s_send(s, t)

	  tN := io.dp3s_iospec_bio3s_send_T(t, newAbsPkt)
	  err := BatchSend(t, newAbsPkt)
	  ghost if(err != 0){
		fold dp.dp3s_iospec_bio3s_send(s, t)
		fold dp.dp3s_iospec_ordered(s, t)
	  } else {
		ghost *ioSharedArg.Place = tN
	  }
	  fold SharedInv!< dp, ioSharedArg !>()
	  ghost ioLock.Unlock()
	}
  }
}

requires dp.Valid()
requires acc(sl.AbsSlice_Bytes(ub, 0, len(ub)), _)
requires IO_val_Abs(ub, dp).isIO_val_Pkt2 ==> ElemWitness(ioSharedArg.IBufY, ifsToIO_ifs(ingressID), IO_val_Abs(ub, dp).IO_val_Pkt2_2)
preserves acc(ioLock.LockP(), _) && ioLock.LockInv() == SharedInv!< dp, ioSharedArg !>;
ensures acc(sl.AbsSlice_Bytes(ub, 0, len(ub)), _)
ensures newAbsPkt.isIO_val_Pkt2 ==> ElemWitness(ioSharedArg.OBufY, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)
ensures newAbsPkt.isIO_val_Pkt2 || newAbsPkt.isIO_val_Unsupported //if err == nil
func processPkt(ub Pkt, ghost ingressID uint16, ghost ioLock *sync.Mutex, ghost ioSharedArg SharedArg, ghost dp io.DataPlaneSpec) (ghost newAbsPkt io.IO_val) {
  var pathType int
  //assume IO_val_Abs(ub).isIO_val_Pkt2 ==> pathType == 1
  //assume pathType == 1 ==> IO_val_Abs(ub).isIO_val_Pkt2
  if pathType == 1 {
	//assume ifsToIO_ifs(ingressID) == IO_val_Abs(ub).IO_val_Pkt2_1
	newAbsPkt = Process(ub, ioLock, ioSharedArg, dp)
	//assume newAbsPkt.isIO_val_Pkt2
	//AssumeElemWitness(ioSharedArg.OBufY, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)
  } else {
	assume newAbsPkt.isIO_val_Unsupported
  }
  return newAbsPkt
}


requires dp.Valid()
requires acc(sl.AbsSlice_Bytes(ub, 0, len(ub)), _)
requires IO_val_Abs(ub, dp).isIO_val_Pkt2 ==> ElemWitness(ioSharedArg.IBufY, IO_val_Abs(ub, dp).IO_val_Pkt2_1, IO_val_Abs(ub, dp).IO_val_Pkt2_2)
preserves acc(ioLock.LockP(), _) && ioLock.LockInv() == SharedInv!< dp, ioSharedArg !>;
ensures acc(sl.AbsSlice_Bytes(ub, 0, len(ub)), _)
ensures newAbsPkt.isIO_val_Pkt2 ==> ElemWitness(ioSharedArg.OBufY, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)
ensures newAbsPkt.isIO_val_Pkt2 || newAbsPkt.isIO_val_Unsupported // if err == nil
func Process(ub Pkt, ghost ioLock *sync.Mutex, ghost ioSharedArg SharedArg, ghost dp io.DataPlaneSpec) (ghost newAbsPkt io.IO_val) {
	ghost absPkt := IO_val_Abs(ub, dp)
   // ghost ingressID := absPkt.IO_val_Pkt2_1
	assume absPkt.isIO_val_Pkt2 //deal with later

	ghost currseg := absPkt.IO_val_Pkt2_2.CurrSeg
	//assume len(currseg.Future) > 0 // true by construction

	ghost hf1, fut := currseg.Future[0], currseg.Future[1:]
	ghost nextif_opt := currseg.ConsDir ? hf1.EgIF2 : hf1.InIF2
	assume absPkt.IO_val_Pkt2_1 != none[io.IO_ifs] ==> currseg.ConsDir ? hf1.InIF2 == absPkt.IO_val_Pkt2_1 : hf1.EgIF2 == absPkt.IO_val_Pkt2_1 //should be easy
	//assume hf1.extr_asid() == dp.Asid() // true by construction
	//Inbound
	ghost if(absPkt.IO_val_Pkt2_1 != none[io.IO_ifs]) {
		if (nextif_opt == none[io.IO_ifs]) {
			// local
			// enter
			ghost traversedseg := io.establishGuardTraversedseg(currseg, !currseg.ConsDir)
			ghost pkt_internal := io.IO_val(io.IO_Internal_val1{
                absPkt.IO_val_Pkt2_2,
                get(absPkt.IO_val_Pkt2_1),
                io.IO_pkt2(
                    io.IO_Packet2{
                        io.establishGuardTraversedseg(currseg, !currseg.ConsDir),
                        absPkt.IO_val_Pkt2_2.LeftSeg,
                        absPkt.IO_val_Pkt2_2.MidSeg,
                        absPkt.IO_val_Pkt2_2.RightSeg}),
                currseg.ConsDir ? currseg.Future[0].EgIF2 : currseg.Future[0].InIF2})


            //localEnterPkt(absPkt)
			assume dp.hf_valid(currseg.ConsDir, currseg.AInfo, traversedseg.UInfo, hf1) //not clear at the moment

			assert dp.dp2_enter_guard(pkt_internal.IO_Internal_val1_1, currseg, traversedseg, dp.Asid(), hf1, pkt_internal.IO_Internal_val1_2, fut)

			ghost ioLock.Lock()
			unfold SharedInv!< dp, ioSharedArg !>()

			t, s := *ioSharedArg.Place, *ioSharedArg.State

			ApplyElemWitness(s.ibuf, ioSharedArg.IBufY, absPkt.IO_val_Pkt2_1, absPkt.IO_val_Pkt2_2)
			assert absPkt.IO_val_Pkt2_2 in AsSet(s.ibuf[absPkt.IO_val_Pkt2_1])
			assert dp.dp3s_iospec_bio3s_enter_guard(s, t, pkt_internal)

			unfold dp.dp3s_iospec_ordered(s, t)
			unfold dp.dp3s_iospec_bio3s_enter(s, t)

			tN := io.CBio_IN_bio3s_enter_T(t, pkt_internal)
			io.Enter(t, pkt_internal) //Event

			newAbsPkt = io.IO_val(io.IO_val_Pkt2{pkt_internal.IO_Internal_val1_4, pkt_internal.IO_Internal_val1_3})
			UpdateElemWitness(s.obuf, ioSharedArg.OBufY, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)

			ghost *ioSharedArg.State = io.dp3s_add_obuf(s, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)
			ghost *ioSharedArg.Place = tN

			fold SharedInv!< dp, ioSharedArg !>()
			ghost ioLock.Unlock()
		} else {
			// Outbound
			if (len(currseg.History) == 0) {
				//xover
				assume absPkt.IO_val_Pkt2_2.LeftSeg != none[io.IO_seg2] // have to prove
				ghost nextseg := get(absPkt.IO_val_Pkt2_2.LeftSeg)
				assume len(nextseg.Future) > 1 // have to prove

				assume nextseg.History == seq[io.IO_ahi]{} //true by construction
				assume currseg.Future == seq[io.IO_HF]{hf1} // have to prove

				ghost traversedseg_inc_curr := io.establishGuardTraversedsegInc(currseg, !currseg.ConsDir)
				ghost traversedseg_inc_next := io.establishGuardTraversedsegInc(nextseg, nextseg.ConsDir) //len(traversedseg_inc_next) > 0

				//next interface
				ghost hf2 := nextseg.Future[0]
				ghost nextif_opt := nextseg.ConsDir ? hf2.EgIF2 : hf2.InIF2
				assume hf2.extr_asid() == dp.Asid() // prove
				// ghost pkt_intermediate := io.IO_pkt2(
				// 	io.IO_Packet2{
				// 			nextseg,
				// 			absPkt.IO_val_Pkt2_2.MidSeg,
				// 			absPkt.IO_val_Pkt2_2.RightSeg,
				// 			some(traversedseg_inc_curr)})

				ghost pkt_internal := io.IO_val(io.IO_Internal_val1{
				absPkt.IO_val_Pkt2_2,
				get(absPkt.IO_val_Pkt2_1),
				io.IO_Packet2{
					traversedseg_inc_next,
					absPkt.IO_val_Pkt2_2.MidSeg,
					absPkt.IO_val_Pkt2_2.RightSeg,
					some(traversedseg_inc_curr)},
				nextif_opt})

				assume dp.hf_valid(currseg.ConsDir, currseg.AInfo, traversedseg_inc_curr.UInfo, hf1)
				assume dp.hf_valid(nextseg.ConsDir, nextseg.AInfo, nextseg.UInfo, hf2) //not clear at the moment
				assume dp.dp2_check_recvif(currseg.ConsDir, dp.Asid(), get(absPkt.IO_val_Pkt2_1)) //to proof
				//assert dp.dp2_xover_common_guard(absPkt.IO_val_Pkt2_2, currseg, nextseg, traversedseg_inc_curr, pkt_intermediate, hf1, hf2, dp.Asid(), get(absPkt.IO_val_Pkt2_1))
				assume dp.dp2_check_interface_top(nextseg.ConsDir, dp.Asid(), hf2) // must be proven

				if(dp.Asid() in dp.Core()){
					assume dp.xover_core2_link_type(hf1, hf2, dp.Asid(), currseg.ConsDir)
					assume currseg.ConsDir == nextseg.ConsDir //deal with later
					assert nextif_opt != none[io.IO_ifs]
					assume get(nextif_opt) in domain(dp.GetNeighborIAs()) // must be proven
					reveal dp.Valid()

					ghost ioLock.Lock()
					unfold SharedInv!< dp, ioSharedArg !>()

					t, s := *ioSharedArg.Place, *ioSharedArg.State

					ApplyElemWitness(s.ibuf, ioSharedArg.IBufY, absPkt.IO_val_Pkt2_1, absPkt.IO_val_Pkt2_2)
					assert absPkt.IO_val_Pkt2_2 in AsSet(s.ibuf[absPkt.IO_val_Pkt2_1])

					assert dp.dp3s_iospec_bio3s_xover_core_guard(s, t, pkt_internal)
					unfold dp.dp3s_iospec_ordered(s, t)
					unfold dp.dp3s_iospec_bio3s_xover_core(s, t)

					tN := io.dp3s_iospec_bio3s_xover_core_T(t, pkt_internal)
					io.Xover_core(t, pkt_internal) //Event

					newAbsPkt = io.IO_val(io.IO_val_Pkt2{pkt_internal.IO_Internal_val1_4, pkt_internal.IO_Internal_val1_3})
					UpdateElemWitness(s.obuf, ioSharedArg.OBufY, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)

					ghost *ioSharedArg.State = io.dp3s_add_obuf(s, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)
					ghost *ioSharedArg.Place = tN

					fold SharedInv!< dp, ioSharedArg !>()
					ghost ioLock.Unlock()
				} else {
					assume !currseg.ConsDir && nextseg.ConsDir //deal with later
					assume dp.xover_up2down2_link_type(dp.Asid(), hf1, hf2)
					assert nextif_opt != none[io.IO_ifs]
					assume get(nextif_opt) in domain(dp.GetNeighborIAs()) // must be proven
					reveal dp.Valid()
					ghost ioLock.Lock()
					unfold SharedInv!< dp, ioSharedArg !>()

					t, s := *ioSharedArg.Place, *ioSharedArg.State

					ApplyElemWitness(s.ibuf, ioSharedArg.IBufY, absPkt.IO_val_Pkt2_1, absPkt.IO_val_Pkt2_2)
					assert absPkt.IO_val_Pkt2_2 in AsSet(s.ibuf[absPkt.IO_val_Pkt2_1])


					assert dp.dp3s_iospec_bio3s_xover_up2down_guard(s, t, pkt_internal)
					unfold dp.dp3s_iospec_ordered(s, t)
					unfold dp.dp3s_iospec_bio3s_xover_up2down(s, t)

					tN := io.dp3s_iospec_bio3s_xover_up2down_T(t, pkt_internal)
					io.Xover_up2down(t, pkt_internal) //Event

					newAbsPkt = io.IO_val(io.IO_val_Pkt2{pkt_internal.IO_Internal_val1_4, pkt_internal.IO_Internal_val1_3})
					UpdateElemWitness(s.obuf, ioSharedArg.OBufY, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)

					ghost *ioSharedArg.State = io.dp3s_add_obuf(s, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)
					ghost *ioSharedArg.Place = tN

					fold SharedInv!< dp, ioSharedArg !>()
					ghost ioLock.Unlock()
				}
			} else{
				//enter
				ghost nextif := get(nextif_opt)
				ghost traversedseg_in := io.establishGuardTraversedseg(currseg, !currseg.ConsDir)
				ghost traversedseg_out := io.establishGuardTraversedsegInc(traversedseg_in, currseg.ConsDir)
				assume nextif in domain(dp.GetNeighborIAs()) // must be proven
				ghost a2 := dp.GetNeighborIA(nextif)
				reveal dp.Valid()
				//  ghost i2 := dp.Lookup(io.AsIfsPair{dp.Asid(), nextif}).ifs
				//  assert dp.is_target(dp.Asid(), nextif, a2, i2) // should be true with dp.Valid()
				//  ghost pkt_tmp := io.IO_pkt2(io.IO_Packet2{
				//				traversedseg_in,
				//				absPkt.IO_val_Pkt2_2.LeftSeg,
				//				absPkt.IO_val_Pkt2_2.MidSeg,
				//				absPkt.IO_val_Pkt2_2.RightSeg})

				ghost pkt_internal := io.IO_val(io.IO_Internal_val1{
					absPkt.IO_val_Pkt2_2,
					get(absPkt.IO_val_Pkt2_1),
					io.IO_pkt2(
						io.IO_Packet2{
							traversedseg_out,
							absPkt.IO_val_Pkt2_2.LeftSeg,
							absPkt.IO_val_Pkt2_2.MidSeg,
							absPkt.IO_val_Pkt2_2.RightSeg}),
					nextif_opt})
				assume dp.dp2_check_interface_top(currseg.ConsDir, dp.Asid(), hf1) // must be proven
				assume dp.hf_valid(currseg.ConsDir, currseg.AInfo, traversedseg_in.UInfo, hf1) //not clear at the moment


				ghost ioLock.Lock()
				unfold SharedInv!< dp, ioSharedArg !>()

				t, s := *ioSharedArg.Place, *ioSharedArg.State

				ApplyElemWitness(s.ibuf, ioSharedArg.IBufY, absPkt.IO_val_Pkt2_1, absPkt.IO_val_Pkt2_2)
				assert absPkt.IO_val_Pkt2_2 in AsSet(s.ibuf[absPkt.IO_val_Pkt2_1])
				// assert dp.dp2_enter_guard(pkt_internal.IO_Internal_val1_1,currseg,traversedseg_in,dp.Asid(),hf1,pkt_internal.IO_Internal_val1_2,fut)
				// assert dp.dp2_forward_ext_guard(dp.Asid(), pkt_tmp, nextif, traversedseg_in, traversedseg_out, pkt_internal.IO_Internal_val1_3, fut, hf1)
				assert dp.dp3s_iospec_bio3s_enter_guard(s, t, pkt_internal)
				unfold dp.dp3s_iospec_ordered(s, t)
				unfold dp.dp3s_iospec_bio3s_enter(s, t)

				tN := io.CBio_IN_bio3s_enter_T(t, pkt_internal)
				io.Enter(t, pkt_internal) //Event

				newAbsPkt = io.IO_val(io.IO_val_Pkt2{pkt_internal.IO_Internal_val1_4, pkt_internal.IO_Internal_val1_3})
				UpdateElemWitness(s.obuf, ioSharedArg.OBufY, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)

				ghost *ioSharedArg.State = io.dp3s_add_obuf(s, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)
				ghost *ioSharedArg.Place = tN

				fold SharedInv!< dp, ioSharedArg !>()
				ghost ioLock.Unlock()
			}
		}
	} else {
		//exit
		assume nextif_opt != none[io.IO_ifs] // have to prove
		ghost nextif := get(nextif_opt)
		ghost traversedseg_out := io.establishGuardTraversedsegInc(absPkt.IO_val_Pkt2_2.CurrSeg, currseg.ConsDir)
		assume nextif in domain(dp.GetNeighborIAs()) // must be proven
		// ghost a2 := dp.GetNeighborIA(nextif)
		// ghost i2 := dp.Lookup(io.AsIfsPair{dp.Asid(), nextif}).ifs
		// assert dp.is_target(dp.Asid(), nextif, a2, i2) // should be true with dp.Valid()
		ghost pkt_internal := io.IO_val(io.IO_Internal_val2{
			absPkt.IO_val_Pkt2_2,
			io.IO_pkt2(io.IO_Packet2{traversedseg_out, absPkt.IO_val_Pkt2_2.LeftSeg, absPkt.IO_val_Pkt2_2.MidSeg, absPkt.IO_val_Pkt2_2.RightSeg}),
			nextif})

		assume dp.dp2_check_interface_top(currseg.ConsDir, dp.Asid(), hf1) // must be proven
		assume dp.hf_valid(currseg.ConsDir, currseg.AInfo, currseg.UInfo, hf1) //not clear at the moment


		ghost ioLock.Lock()
		unfold SharedInv!< dp, ioSharedArg !>()

		t, s := *ioSharedArg.Place, *ioSharedArg.State

		ApplyElemWitness(s.ibuf, ioSharedArg.IBufY, absPkt.IO_val_Pkt2_1, absPkt.IO_val_Pkt2_2)
		assert absPkt.IO_val_Pkt2_2 in AsSet(s.ibuf[absPkt.IO_val_Pkt2_1])


		assert dp.dp3s_iospec_bio3s_exit_guard(s, t, pkt_internal)

		unfold dp.dp3s_iospec_ordered(s, t)
		unfold dp.dp3s_iospec_bio3s_exit(s, t)

		tN := io.dp3s_iospec_bio3s_exit_T(t, pkt_internal)
		io.Exit(t, pkt_internal) //Event

		newAbsPkt = io.IO_val(io.IO_val_Pkt2{some(pkt_internal.IO_Internal_val2_3), pkt_internal.IO_Internal_val2_2})
		UpdateElemWitness(s.obuf, ioSharedArg.OBufY, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)

		ghost *ioSharedArg.State = io.dp3s_add_obuf(s, newAbsPkt.IO_val_Pkt2_1, newAbsPkt.IO_val_Pkt2_2)
		ghost *ioSharedArg.Place = tN

		fold SharedInv!< dp, ioSharedArg !>()
		ghost ioLock.Unlock()

	}
}


/** ATOMIC BIO operations **/

ghost
requires dp.Valid()
requires ingressID != none[io.IO_ifs]
requires len(oldPkt.CurrSeg.Future) > 0
requires ElemWitness(ioSharedArg.IBufY, ingressID, oldPkt)
requires dp.dp2_enter_guard(
			oldPkt,
			oldPkt.CurrSeg,
			io.establishGuardTraversedseg(oldPkt.CurrSeg, !oldPkt.CurrSeg.ConsDir),
			dp.Asid(),
			oldPkt.CurrSeg.Future[0],
			get(ingressID),
			oldPkt.CurrSeg.Future[1:])
requires dp.dp3s_forward(
				io.IO_pkt2(
					io.IO_Packet2{
						io.establishGuardTraversedseg(oldPkt.CurrSeg, !oldPkt.CurrSeg.ConsDir),
						oldPkt.LeftSeg,
						oldPkt.MidSeg,
						oldPkt.RightSeg}),
				newPkt,
			    egressID)
preserves acc(ioLock.LockP(), _) && ioLock.LockInv() == SharedInv!< dp, ioSharedArg !>;
ensures ElemWitness(ioSharedArg.OBufY, egressID, newPkt)
decreases _
func AtomicEnter(oldPkt io.IO_pkt2, ingressID option[io.IO_ifs], newPkt io.IO_pkt2, egressID option[io.IO_ifs], ioLock *sync.Mutex, ioSharedArg SharedArg, dp io.DataPlaneSpec) {
    ghost ioLock.Lock()
	unfold SharedInv!< dp, ioSharedArg !>()

	t, s := *ioSharedArg.Place, *ioSharedArg.State

	ApplyElemWitness(s.ibuf, ioSharedArg.IBufY, ingressID, oldPkt)
    ghost pkt_internal := io.IO_val(io.IO_Internal_val1{
                oldPkt,
                get(ingressID),
                newPkt,
                egressID})


	assert dp.dp3s_iospec_bio3s_enter_guard(s, t, pkt_internal)
	unfold dp.dp3s_iospec_ordered(s, t)
	unfold dp.dp3s_iospec_bio3s_enter(s, t)

	tN := io.CBio_IN_bio3s_enter_T(t, pkt_internal)
	io.Enter(t, pkt_internal) //Event

	UpdateElemWitness(s.obuf, ioSharedArg.OBufY, egressID, newPkt)

	ghost *ioSharedArg.State = io.dp3s_add_obuf(s, egressID, newPkt)
	ghost *ioSharedArg.Place = tN

	fold SharedInv!< dp, ioSharedArg !>()
	ghost ioLock.Unlock()
}